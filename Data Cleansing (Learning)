import pandas as pd
import numpy as np
from pandas.core.indexes.base import Index
import matplotlib.pyplot as plt
from sty import fg, bg, ef, rs
from matplotlib.ticker import MultipleLocator, MaxNLocator

# ----------- Some work following online examples, teaching myself how to cleanse and graph data ---------------

# Read CSV and use Shape to get count of rows, columns
df = pd.read_csv("reddit_vm.csv")
df.shape

# Find % of values missing / NaN
values_list = list()
cols_list = list()
for col in df.columns:
    pct_missing = np.mean(df[col].isnull()) * 100
    cols_list.append(col)
    values_list.append(pct_missing)
    
# Build dataframe from lists
df_pct_missing = pd.DataFrame()
df_pct_missing['col'] = cols_list
df_pct_missing['pct_missing'] = values_list
# Another option is to do lists -> dictionary -> dataframe
# dict_pct_missing = {'col': cols_list, 'pct_missing': values_list}
# df_pct_missing = pd.DataFrame(dict_pct_missing)

# Plot the results
df_filtered = df_pct_missing.loc[df_pct_missing.pct_missing > 0]
# (by default 'use_index=True')
# bar_graph = df_pct_missing.loc[df_pct_missing.pct_missing > 0].plot(kind='bar', figsize=(12,8), xlabel='Column Index Number', ylabel='% Values Missing', fontsize=12, x='col')
# rot=0 means rotation set to 0 on axis 
bar_graph = df_filtered.plot(kind='bar', figsize=(12,8), xlabel='Column Index Number', ylabel='% Values Missing', fontsize=11, x='col', table=False, rot=0)


# Drop columns with % of null values between 0 - 0.5%
list_less_pct_missing = list(df_pct_missing.loc[(df_pct_missing.pct_missing < 0.5) & (df_pct_missing.pct_missing > 0), 'col'].values)
df.dropna(subset=list_less_pct_missing, inplace=True)

# Drop columns with more than 40% null values
list_40_pct_missing = list(df_pct_missing.loc[(df_pct_missing.pct_missing > 40), 'col'].values)
df.drop(columns=list_40_pct_missing, inplace=True)

# Find numerical values
df_numeric = df.select_dtypes(include=[np.number])
numeric_cols = df_numeric.columns.values
# print(f'Numeric columns: {numeric_cols}')  

# Find non-numerical values
df_non_numeric = df.select_dtypes(exclude=[np.number])
non_numeric_cols = df_non_numeric.columns.values
# print(f'Non-numeric columns: {non_numeric_cols}')  

# Impute missing values
# Replace missing values with the median value in each column
for col in numeric_cols:
    missing = df[col].isnull()
    num_missing = np.sum(missing)
    if num_missing > 0:
        med = df[col].median()
        df[col] = df[col].fillna(med) 

# Replace missing non-numeric values with the mode value (top string)
for col in non_numeric_cols:
    missing = df[col].isnull()
    num_missing = np.sum(missing)
    if num_missing > 0:  # impute values only for columns that have missing values
        mod = df[col].describe()['top'] # impute with the most frequently occuring value
        df[col] = df[col].fillna(mod)
        
if df.isnull().sum().sum() == 0:
    print(f'{bg.green}{fg.black}All missing values have been dealt with{bg.rs}{fg.rs}')
else:
    print(f'{fg.red}Missing values still need to be dealt with{fg.rs}')

# df.score.describe()
# df.score.mean()  # returns the mean of entire column
# df.score.mean    # returns the mean for each row in column

# Graph a boxplot to show any outliers
# Max value 1187 is an outlier on its own
df_scores = pd.DataFrame(df.score)
df_scores.plot(kind='box', figsize=(8, 8))
plt.show()

# removing the outlier value
max_value = df.score.max()
df = df.loc[df.score < max_value]

df_scores = pd.DataFrame(df.score)
df_scores.plot(kind='box', figsize=(8, 8))
plt.show()

# dropping duplicates by considering all columns other than ID
cols_other_than_id = list(df.columns)[1:]
df.drop_duplicates(subset=cols_other_than_id, inplace=True)

# converting timestamp to datetime and adding a date column
df.created.dtype
# df['created'] = pd.to_datetime(df.created, format='%Y-%m-%d')  # Changes format of object, but cannot do this with epoch
df['timestamp'] = df['timestamp'].astype('datetime64[ns]')
df['date'] = df['timestamp'].dt.date
df.to_csv("Data_Cleansed")
